La CPU è il cervello del computer, ed è composta dall’unità di controllo (CU), l’unità aritmetica e logica (ALU) e alcuni registri (piccole memorie ad altissima velocità).

Tra i registri sono molto importanti:  

- **Program Counter (PC):** ==Punta alla prossima istruzione da prelevare per l’esecuzione;==
- **Instruction Register (IR):** ==Mantiene l’istruzione corrente in fase di esecuzione dell'istruzione.==

Le componenti di un computer sono collegate attraverso un **bus**, cioè una ==collezione di cavi paralleli utilizzati per trasferire indirizzi, dati e segnali di controllo.==

---
## **Organizzazione della CPU**

Il percorso dati (data path) di una tipica CPU di von Neumann è composta dai registri (da 1 a 32), dalla ALU e da alcuni bus che connettono fra loro le diverse parti.

I registri alimentano due registri di input della ALU che mantengono i dati di ingresso della ALU mentre questa è occupata nell’esecuzione di alcune computazioni.

==La ALU esegue alcune semplici operazioni sui suoi input, come addizioni, sottrazioni generando un risultato che viene memorizzato in un suo apposito registro di output==, questo valore può essere successivamente immagazzinato in uno dei registri della CPU che, volendo, può essere copiato in memoria in un secondo momento.

La maggior parte delle istruzioni può essere divisa in due categorie principali:

- **istruzioni registro-memoria** (necessita di una fase di caricamento delle parole della memoria nei registri): permettono di prelevare parole di memoria per portarle all’interno dei registri (o viceversa), dove sono utilizzabili, per esempio, come input della ALU per effettuare istruzioni successive.

- **istruzioni registro-registro** (gli operandi sono già pronti nei registri): preleva due operandi dai registri, li porta all’interno dei registri di input della ALU, esegue su di loro una qualche operazione e ne memorizza il risultato in uno dei registri.

## Esecuzione dell'istruzione

La CPU esegue ogni istruzione compiendo una serie di passi:

1. prelevare la successiva istruzione dalla memoria per portarla nell’IR;
2. aggiornare il PC per farlo puntare all’istruzione seguente;
3. determinare il tipo dell’istruzione appena prelevata (decodifica dell’istruzione);
4. se l’istruzione usa una parola in memoria, determinare dove si trova;
5. se necessario, prelevare la parola per portarla in un registro della CPU;
6. eseguire l’istruzione;
7. tornare al punto 1 per iniziare l’esecuzione dell’istruzione successiva.

Spesso ci si riferisce a questa sequenza di passi con il termine di ciclo esecutivo delle istruzioni, o ciclo di prelievo-decodifica-esecuzione (**fetch-decode-execute**).
## **Strategie di progettazione delle CPU**

- **CISC** (Complex Instruction Set Computer): la CPU è in grado di comprendere molte istruzioni complesse nativamente (è il più alto livello di astrazione riconosciuto dalla macchina);

- **RISC** (Reduced Instruction Set Computer): si basa sull’idea che se le istruzioni sono semplici e poche, esse possono essere eseguite rapidamente (è necessario un solo ciclo nel datapath);

- **Ibrido**: a partire dal x486, le CPU intel contengono un sottoinsieme di istruzioni RISC (quelle più comuni) che possono essere eseguite in un singolo ciclo nel datapath, mentre le altre complesse sono interpretate secondo la classica modalità CISC.
## **Principi di progettazione dei calcolatori moderni**

Esiste un insieme di principi di progettazione, talvolta chiamati principi di progettazione RISC, che i progettisti delle CPU cercano di seguire il più possibile.

**Tutte le istruzioni devono essere eseguite direttamente dall’hardware:** Le istruzioni non devono essere interpretate. Per le architettura CISC, quelle istruzioni più complesse (e più rare) possono essere suddivise in parti ed eseguite, successivamente, come sequenze di microistruzioni.

**Massimizzare la frequenza di emissione delle istruzioni:** Il parallelismo gioca un ruolo essenziale nelle prestazioni di un computer. Infatti è possibile emettere un gran numero di lente istruzioni in un breve intervallo di tempo solo se si riescono a eseguire più istruzioni allo stesso tempo.

**Le istruzioni devono essere facili da decodificare:** Un limite critico sulla frequenza di emissione delle istruzioni è dato dal processo di decodifica, che deve essere effettuato per ogni singola istruzione allo scopo di determinare le risorse necessarie. Bisogna rendere le istruzioni regolari, di lunghezza fissa e con pochi campi. Meno formati di istruzioni ci sono, meglio è.

**Solo le istruzioni Load e Store fanno riferimento alla memoria:** Dato che l’accesso alla memoria può richiedere un tempo considerevole, queste operazioni possono essere efficientemente sovrapposte all’esecuzione di altre istruzioni quindi soltanto le istruzioni LOAD e STORE dovrebbero far riferimento alla memoria, mentre tutte le altre dovrebbero operare esclusivamente sui registri.

**Molti registri disponibili:** Dato che l’accesso alla memoria è relativamente lento occorre prevedere molti registri (almeno 32) di modo che, una volta prelevata la parola, possa essere mantenuta nel registro fintanto sia necessario. È particolarmente inefficiente trovarsi senza registri liberi, in quanto obbliga a scaricare in memoria tutti i valori dei registri per poi ricaricarli.
## **Parallelismo a livello di istruzione**

 Poiché l’incremento del clock del processore ha raggiunto un limite fisico ([[Intel]]), i progettisti di CPU guardano al parallelismo (più istruzioni nello stesso tempo) per incrementare le prestazioni.

Il parallelismo si può ottenere in due diversi modi:  

 - **Parallelismo a livello di processore**: Paragrafo successivo

- **Parallelismo a livello di istruzione**: il parallelismo è sfruttato all’interno delle istruzioni per ottenere un maggior numero di istruzioni al secondo. le tecniche più usate sono:
 
  - **Pipelining**: ==Una limitazione nella velocità di esecuzione delle istruzioni è rappresentato dal prelievo delle istruzioni dalla memoria.==
  
   Per alleviare questo problema, i ==calcolatori sono stati dotati della capacità di poter prelevare in anticipo le istruzioni dalla memoria==, in modo da averle già a disposizione nel momento in cui dovessero rendersi necessarie. 
   
   Le istruzioni venivano memorizzate in un insieme di registri chiamati **buffer di prefetch**, dai quali potevano essere prese nel momento in cui venivano richieste, senza dover attendere che si completasse una lettura della memoria.
   
   In pratica la tecnica di **prefetching** divide l’esecuzione dell’istruzione in due parti: 

    - il prelievo dell’istruzione 
    - la sua esecuzione effettiva.

   ==Il pipeline divide l’esecuzione di un’istruzione in un numero maggiore di parti che possono essere eseguite in parallelo; ciascuna di queste parti è gestita da componenti hardware dedicati.==
   
   ==Il pipelining permette di bilanciare la latenza (quanto dura l’esecuzione di una istruzione) con la banda del processore (quanti MIPS la CPU è in grado di  emettere).==

   Una CPU, senza pipeline, che opera con clock di T ns ed emette una istruzione per ciclo di clock ha una banda di 103/T MIPS.

   Supponendo di disporre di una CPU con un clock di T ns e una pipeline a P stadi (in cui ogni stadio necessita di un ciclo di clock per essere completato), la latenza totale è pari a P **·** T ns mentre la banda è P **·** 103/T MIPS, cioè P volte rispetto alla banda di una CPU senza pipeline con medesima latenza.
 
| ciclo di clock |          1°          |           2°            |                 3°                  |                 4°                  |                 5°                  |
| :------------: | :------------------: | :---------------------: | :---------------------------------: | :---------------------------------: | :---------------------------------: |
|  **Stadio 1**  | Preleva istruzione 1 |  Preleva istruzione 2   |        Preleva istruzione 3         |        Preleva istruzione 4         |        Preleva istruzione 5         |
|  **Stadio 2**  |          //          | Decodifica Istruzione 1 |       Decodifica Istruzione 2       |       Decodifica Istruzione 3       |       Decodifica Istruzione 4       |
|  **Stadio 3**  |          //          |           //            | Preleva operandi per l’istruzione 1 | Preleva operandi per l’istruzione 2 | Preleva operandi per l’istruzione 3 |
|  **Stadio 4**  |          //          |           //            |                 //                  |         Esegue istruzione 1         |         Esegue istruzione 2         |
|  **Stadio 5**  |          //          |           //            |                 //                  |                 //                  |    Scrive risultato istruzione 1    |


  - **Processori con più pipeline**:

    Avere due pipeline è sicuramente meglio di averne una sola, questa architettura è stata utilizzata inizialmente dall’Intel x486.

    ==Affinché le due istruzioni possano essere eseguite in parallelo, non devono però esserci conflitti nell’uso delle risorse (cioè i registri) e nessuna delle due istruzioni deve dipendere dal risultato dell’altra.==

    Inoltre, non tutte le istruzioni possono essere svolte in parallelo (l’input di una istruzione può dipendere dal risultato della precedente) e sarebbero necessarie troppe componenti hardware per le varie unità che andrebbero poi sincronizzate.
    
![[Pipeline2.png]]


  - **Architetture Superscalari**:

    Viene utilizzata inizialmente da Intel Core. Il processore dispone di una sola pipeline con più unità funzionali in corrispondenza di alcuni stadi.

    ==Affinché l’architettura abbia senso è necessario che la velocità di emissione della fase S3 sia più alta rispetto a quella della fase S4.==

    La fase S4 può avere delle unità ALU duplicate.
    
![[Superscalare.png]]

## **Parallelismo a livello di processore**

Il parallelismo nel chip aiuta a migliorare le performance della CPU: con il pipelining e le architetture superscalari si può arrivare ad un fattore di miglioramento da 5 a 10.

==Però per incrementare drasticamente le performance di un calcolatore occorre progettare sistemi con molte CPU, in questo caso si può arrivare ad ottenere un incremento di 50, 100, o anche più.==

Esistono tre differenti approcci:

 - **Computer con parallelismo sui dati**:  
   Ci sono due schemi differenti:

    - **Processori SIMD (Single Instruction-stream Multiple Data-stream):** sono costituiti da un ==vasto numero di processori identici che eseguono la stessa sequenza di istruzioni su insieme differenti di dati==;

    - **Processori vettoriali:** ==un processore vettoriale esegue la stessa sequenza di operazioni su coppie di dati==, ma tutte le addizioni sono svolte da un unico sommatore strutturato in pipeline.

   Entrambe le architettura lavorano su array di dati, mentre il primo utilizza tanti sommatori quanti gli elementi del vettore, il secondo utilizza un solo sommatore e un unico registro vettoriale.
   
- **Multiprocessori**: ==È un’architettura costituita da più CPU che condividono una memoria comune.==
  Poiché ciascuna CPU può leggere o scrivere qualsiasi zona della memoria comune, le CPU devono sincronizzarsi via software.
  In questo caso le CPU hanno la necessità di interagire in modo così profondo che il sistema è detto fortemente accoppiato (**tightly coupled**).
  
	- **Multicomputer**:  Multiprocessori con molte CPU sono difficili da realizzare, per via del problema delle connessioni di ciascuna CPU verso la memoria comune.
  I progettisti hanno superato il problema abbandonando il concetto di memoria comune e ==realizzando un elevato numero di CPU interconnesse, ciascuna con la propria memoria privata.==
  Le CPU in un multicomputer sono accoppiate in modo lasco (**loosely coupled**) e comunicano attraverso scambi di messaggi.
  In architetture grandi la completa interconnessione non è fattibile così sono utilizzate topologie differenti come la griglia, l’albero o l’anello.